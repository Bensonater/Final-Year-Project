{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from logging import getLogger, ERROR\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "# Fix module imports\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Disable Hugging Face warnings\n",
    "getLogger(\"transformers.modeling_utils\").setLevel(ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, Series\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "from concrete.ml.sklearn import SGDClassifier\n",
    "from concrete.fhe.compilation import Configuration\n",
    "from model.qgpt2_models import QGPT2ClassificationModel\n",
    "import time\n",
    "\n",
    "model = GPT2Model.from_pretrained(\"openai-community/gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fhe_model = QGPT2ClassificationModel.from_pretrained(\"./saved_model\", n_bits=8,use_cache=False, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "fhe_model.config.pad_token_id = fhe_model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(\"../data/Tweets.csv\")\n",
    "# df = df[df['airline_sentiment'] != \"neutral\"]\n",
    "\n",
    "# df['airline_sentiment'] = df['airline_sentiment'].replace([\"negative\", \"positive\"], [0, 1])\n",
    "\n",
    "df[\"airline_sentiment\"] = df[\"airline_sentiment\"].replace(\n",
    "    [\"negative\", \"neutral\", \"positive\"], [0, 1, 2]\n",
    ")\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.select_columns([\"text\", \"airline_sentiment\"])\n",
    "dataset = dataset.rename_column(\"airline_sentiment\", \"label\")\n",
    "\n",
    "ds_dict = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = ds_dict[\"train\"]\n",
    "eval_ds = ds_dict[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that transforms a list of texts to their representation\n",
    "# learned by the transformer.\n",
    "\n",
    "def get_hidden_states(\n",
    "    inputs: list,\n",
    "    transformer_model,\n",
    "    tokenizer: GPT2Tokenizer,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    # Tokenize each text in the list one by one\n",
    "    tokenized = map(lambda x: tokenizer.encode(x, return_tensors=\"pt\"), inputs)\n",
    "\n",
    "    # Send the model to the device\n",
    "    transformer_model = transformer_model.to(device)\n",
    "    output_hidden_states_list = []\n",
    "\n",
    "    for tokenized_x in tokenized:\n",
    "        # Pass the tokens through the transformer model and get the hidden states\n",
    "        # Only keep the last hidden layer state for now\n",
    "        output_hidden_states = transformer_model(tokenized_x.to(device), output_hidden_states=True)[0]\n",
    "        # Average over the tokens axis to get a representation at the text level.\n",
    "        output_hidden_states = output_hidden_states.mean(dim=1)\n",
    "        output_hidden_states = output_hidden_states.detach().cpu().numpy()\n",
    "        output_hidden_states_list.append(output_hidden_states)\n",
    "\n",
    "    return numpy.concatenate(output_hidden_states_list, axis=0)\n",
    "\n",
    "hidden_states = get_hidden_states(train_ds[\"text\"], model, tokenizer)\n",
    "x_test_states = get_hidden_states(eval_ds[\"text\"], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savetxt(\"train_hidden_states.csv\", hidden_states, delimiter=\",\")\n",
    "numpy.savetxt(\"test_hidden_states.csv\", x_test_states, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13176])\n",
      "Epoch [1/3], Loss: 0.9978\n",
      "Epoch [2/3], Loss: 0.9681\n",
      "Epoch [3/3], Loss: 0.9563\n",
      "Run time: 0.0005 seconds\n",
      "Macro F1: 0.4268\n",
      "F1 score for negative class: 0.8131\n",
      "F1 score for neutral class: 0.2613\n",
      "F1 score for positive class: 0.2059\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch import no_grad, tensor, max\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "y_train = tensor(train_ds[\"label\"])\n",
    "y_test = tensor(eval_ds[\"label\"])\n",
    "\n",
    "# num_labels is 3\n",
    "score = Linear(768, 3, bias=False)\n",
    "\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = SGD(\n",
    "    score.parameters(),\n",
    "    lr=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")  # Stochastic Gradient Descent\n",
    "\n",
    "batch_size = 16\n",
    "dataset = TensorDataset(tensor(hidden_states), y_train)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3  # Number of training epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = score(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "with no_grad():\n",
    "    start = time.perf_counter()\n",
    "    outputs = score(tensor(x_test_states))\n",
    "    end = time.perf_counter()\n",
    "    _, y_pred = max(outputs, 1)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    f1s = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "print(f\"Run time: {end - start:.4f} seconds\")\n",
    "print(f\"Macro F1: {f1:.4f}\")\n",
    "print(f\"F1 score for negative class: \" f\"{f1s[0]:.4f}\")\n",
    "print(f\"F1 score for neutral class: \" f\"{f1s[1]:.4f}\")\n",
    "print(f\"F1 score for positive class: \" f\"{f1s[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using encrypted SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SGDClassifier(\n",
    "            random_state=42,\n",
    "            max_iter=1000,\n",
    "            # fit_encrypted=True,\n",
    "            # parameters_range=(-2**8, 2**8),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Series(train_ds[\"label\"])\n",
    "y_test = Series(eval_ds[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics\n",
      "--------------------------------------------------------------------------------\n",
      "size_of_inputs: 8792064\n",
      "size_of_outputs: 34344\n",
      "programmable_bootstrap_count: 0\n",
      "key_switch_count: 0\n",
      "packing_key_switch_count: 0\n",
      "clear_addition_count: 3\n",
      "clear_addition_count_per_parameter: {\n",
      "    LweSecretKeyParam(dimension=1430): 3\n",
      "}\n",
      "encrypted_addition_count: 3075\n",
      "encrypted_addition_count_per_parameter: {\n",
      "    LweSecretKeyParam(dimension=1430): 3075\n",
      "}\n",
      "clear_multiplication_count: 2305\n",
      "clear_multiplication_count_per_parameter: {\n",
      "    LweSecretKeyParam(dimension=1430): 2305\n",
      "}\n",
      "encrypted_negation_count: 3\n",
      "encrypted_negation_count_per_parameter: {\n",
      "    LweSecretKeyParam(dimension=1430): 3\n",
      "}\n",
      "size_of_secret_keys: 11440\n",
      "size_of_bootstrap_keys: 0\n",
      "size_of_keyswitch_keys: 0\n",
      "p_error: 4.89428633255962e-13\n",
      "global_p_error: 1.4682858997671677e-12\n",
      "complexity: 1430.0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Run time: 116.7409 seconds\n",
      "Macro F1: 0.4381\n",
      "F1 score for negative class: 0.8227\n",
      "F1 score for positive class: 0.2907\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(hidden_states, y_train)\n",
    "\n",
    "classifier.compile(hidden_states, configuration=Configuration(show_statistics=True))\n",
    "\n",
    "\n",
    "start = time.perf_counter()\n",
    "y_pred = classifier.predict(x_test_states, fhe=\"execute\")\n",
    "end = time.perf_counter()\n",
    "\n",
    "\n",
    "\n",
    "f1 = f1_score(\n",
    "    y_test, y_pred, average=\"macro\"\n",
    ")\n",
    "\n",
    "f1s = f1_score(\n",
    "    y_test, y_pred, average=None\n",
    ")\n",
    "\n",
    "print(f\"Run time: {end - start:.4f} seconds\")\n",
    "print(f\"Macro F1: {f1:.4f}\")\n",
    "print(f\"F1 score for negative class: \" f\"{f1s[0]:.4f}\")\n",
    "print(f\"F1 score for positive class: \" f\"{f1s[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for positive class: 0.2008\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 score for positive class: \" f\"{f1s[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-2 baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2ForSequenceClassification\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"openai-community/gpt2\", num_labels=3)\n",
    "\n",
    "for param in model.transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
